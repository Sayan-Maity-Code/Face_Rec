{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6732b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d2e4653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceNet loaded; input shape: (None, None, None, 3)\n"
     ]
    }
   ],
   "source": [
    "#Instantiate FaceNet wrapper\n",
    "embedder = FaceNet()  # automatically downloads & loads the model\n",
    "facenet_model = embedder.model  # underlying Keras model\n",
    "print(f\"FaceNet loaded; input shape: {facenet_model.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad631e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "\n",
    "def extract_face_from_frame(frame, required_size=(160, 160)):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = detector.detect_faces(image)\n",
    "    if not results:\n",
    "        return None\n",
    "    x1, y1, w, h = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + w, y1 + h\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, required_size)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e26ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedder and dataset functions\n",
    "def get_embedding(face_pixels):\n",
    "    # use wrapper's preprocess and embed methods\n",
    "    emb = embedder.embeddings([face_pixels])\n",
    "    return emb[0]\n",
    "\n",
    "# Load existing dataset images and compute embeddings\n",
    "def load_dataset_embeddings(dataset_path='dataset/'):\n",
    "    faces, names = [], []\n",
    "    for person in os.listdir(dataset_path):\n",
    "        person_dir = os.path.join(dataset_path, person)\n",
    "        for img_name in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            face = extract_face_from_frame(img)\n",
    "            if face is None: continue\n",
    "            faces.append(face)\n",
    "            names.append(person)\n",
    "    embeddings = [get_embedding(f) for f in faces]\n",
    "    return np.asarray(embeddings), np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8a56295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing classifier and encoders.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "def train_classifier(embeddings, names):\n",
    "    # Expecting embeddings shape (num_samples, feat_dim)\n",
    "    if embeddings.size == 0 or names.size == 0:\n",
    "        raise ValueError(\"No data available for training. Add some face images first.\")\n",
    "    # Normalize embeddings\n",
    "    in_enc = Normalizer(norm='l2')\n",
    "    emb_norm = in_enc.transform(embeddings)\n",
    "    # Encode labels\n",
    "    out_enc = LabelEncoder()\n",
    "    y = out_enc.fit_transform(names)\n",
    "    # If only one class, use KNN to avoid SVM errors\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    if len(out_enc.classes_) == 1:\n",
    "        print(f\"Only one identity ('{out_enc.classes_[0]}') found. Using KNN classifier (k=1) to handle single class.\")\n",
    "        model = KNeighborsClassifier(n_neighbors=1)\n",
    "    else:\n",
    "        # Train SVM for multi-class\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(emb_norm, y)\n",
    "    # Save artifacts\n",
    "    with open('svc_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open('in_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(in_enc, f)\n",
    "    with open('out_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(out_enc, f)\n",
    "    print('Training complete; classifier and encoders saved.')\n",
    "    return model, in_enc, out_enc\n",
    "\n",
    "# Initial train or load\n",
    "try:\n",
    "    if os.path.exists('svc_classifier.pkl'):\n",
    "        # Load existing classifier\n",
    "        with open('svc_classifier.pkl', 'rb') as f:\n",
    "            svc_model = pickle.load(f)\n",
    "        with open('in_encoder.pkl', 'rb') as f:\n",
    "            in_encoder = pickle.load(f)\n",
    "        with open('out_encoder.pkl', 'rb') as f:\n",
    "            out_encoder = pickle.load(f)\n",
    "        print('Loaded existing classifier and encoders.')\n",
    "    else:\n",
    "        # No existing model: attempt to train from dataset\n",
    "        print('No existing classifier found — attempting initial training from dataset...')\n",
    "        emb, names = load_dataset_embeddings()\n",
    "        if names.size == 0:\n",
    "            print(\"[Warning] Dataset folder is empty. Please add a new person first via the interactive cell.\")\n",
    "        else:\n",
    "            svc_model, in_encoder, out_encoder = train_classifier(emb, names)\n",
    "except (ValueError, NotFittedError) as e:\n",
    "    print(f\"Error during training/loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6a7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press SPACE to capture image for recognition.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Recognized as: Sayan2\n"
     ]
    }
   ],
   "source": [
    "#Add new identity or recognize existing\n",
    "choice = input(\"Is this a new person? (yes/no): \").strip().lower()\n",
    "if choice == 'yes':\n",
    "    name = input(\"Enter new person name: \").strip()\n",
    "    save_dir = os.path.join('dataset', name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    cv2.namedWindow('Capture')\n",
    "    print(\"Press SPACE to capture 3 face images.\")\n",
    "    while count < 3:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        cv2.imshow('Capture', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(' '):  # SPACE key\n",
    "            face = extract_face_from_frame(frame)\n",
    "            if face is not None:\n",
    "                img_bgr = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(save_dir, f'{count+1}.jpg'), img_bgr)\n",
    "                count += 1\n",
    "                print(f\"Saved image {count}/3\")\n",
    "    cam.release()\n",
    "    cv2.destroyWindow('Capture')\n",
    "    # Retrain classifier with new data\n",
    "    emb, names = load_dataset_embeddings()\n",
    "    svc_model, in_encoder, out_encoder = train_classifier(emb, names)\n",
    "    print(f\"Added '{name}' and retrained model.\")\n",
    "\n",
    "# Recognition branch (no extra prompts)\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('Recognize')\n",
    "print(\"Press SPACE to capture image for recognition.\")\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    cv2.imshow('Recognize', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(' '):  # SPACE key\n",
    "        face = extract_face_from_frame(frame)\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyWindow('Recognize')\n",
    "\n",
    "# Prediction\n",
    "emb_vec = get_embedding(face)\n",
    "emb_norm = in_encoder.transform([emb_vec])\n",
    "pred = svc_model.predict(emb_norm)\n",
    "print(f\"Recognized as: {out_encoder.inverse_transform(pred)[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
